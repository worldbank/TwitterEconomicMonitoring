{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1uId6X7aAQupJMnEOt1xhQ80PpGnOx_NQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: tweet extraction from the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description and requirements: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will learn how to extract tweets and information about Twitter users from the Twitter API in Python. \n",
    "\n",
    "A requirement for this code to work is to have Twitter API keys and access tokens. The steps to request the latter are described in [this tutorial](https://www.slickremix.com/docs/how-to-get-api-keys-and-tokens-for-twitter/). \n",
    "\n",
    "Also, on top of the usual Python modules (numpy and pandas), you will need to install the [tweepy](http://docs.tweepy.org/en/latest/index.html) package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Google Colaboratory\n",
    "\n",
    "In case you are inexperienced with python and jupyter notebooks, I would recommend using Google Colaboratory (short for Colab).\n",
    "which is free and requires minimal time investment, and it is very easy to start using it.\n",
    "You can simply go to [Colab](https://colab.research.google.com) Sign-In with your Google account, and you are ready to go.\n",
    "tweepy is already installed and ready to use in colab, so all that is left to do is the following:\n",
    "- File -> Upload Notebook\n",
    "- Upload Tab / GitHub\n",
    "- Browse for the .ipynb notebook / Paste the link from GitHub\n",
    "- Run each cell with code using the play symbol next to it (Ctrl+Enter)\n",
    "- Or you can click Runtime -> Run all (Ctrl+F9)\n",
    "\n",
    "Make sure that if you are running each cell to execute them by their order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, please replace the placeholders below by your API credentials. Make sure to keep them private and remove them before sharing this notebook with third-parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "api_dict = {\"API Key\": \"Please Enter Your API key\",\n",
    "             \"API Secret Key\": \"Please Enter Your API Secret Key\",\n",
    "             \"access_token\": \"Please Enter Your access_token\",\n",
    "             \"access_token_secret\": \"Please Enter Your access_token_secret\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have informed your credentials, we will check whether the API recognizes them as valid credentials. The function below will do this and return an error if this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth(api_dict):\n",
    "    # OAuth process, using the keys and tokens\n",
    "    auth = tweepy.OAuthHandler(api_dict['API Key'], api_dict['API Secret Key'])\n",
    "    auth.set_access_token(api_dict['access_token'], api_dict['access_token_secret'])\n",
    "\n",
    "    # Creation of the actual interface, using authentication\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    try:\n",
    "        api.verify_credentials()\n",
    "    except:\n",
    "        print(api_dict, \": error during authentication\")\n",
    "        sys.exit('Exit')\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials Checked!\n"
     ]
    }
   ],
   "source": [
    "get_auth(api_dict)\n",
    "print('Credentials Checked!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Twitter API allows developers to download several types of information on the social network and its users. In this section, we will focus on three types of data:\n",
    "- tweets by hashtag\n",
    "- tweets by user\n",
    "- list of users that a given user follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go on, please note that each developer is limited in the amount of requests she can make to the Twitter API. This is important to take into account if you want to download an important number of tweets. You will find more information on the API rate limit in the [FAQ](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/faq) of the Twitter Developer documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to select which tweets to download is to base this selection on hashtags. This can be relevant if you want to study the importance of specific topics in the Twitter-verse and what users have to say about these topics.\n",
    "\n",
    "The function below takes as input:\n",
    "- the `api_dict` dictionary, containing our credentials and defined earlier\n",
    "- a list of hashtags `tags_list`\n",
    "- `language` the language of the tweet\n",
    "- `count_int` the number of tweets to download per hashtag\n",
    "\n",
    "It then loops over the list of hashtags, downloads `count_int` tweets per hashtag and return tweets and related information in a Pandas dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_tags(api_dict, tags_list, language, count_int):\n",
    "    # Create Access For Block of Users\n",
    "    api = get_auth(api_dict)\n",
    "\n",
    "    tweets = []\n",
    "    for tag in tags_list:\n",
    "        try:\n",
    "            cursor = tweepy.Cursor(\n",
    "                api.search,\n",
    "                q=f'#{tag}',\n",
    "                language=language).items(count_int)\n",
    "            for tweet in cursor:\n",
    "                tweets.append(tweet)\n",
    "        except tweepy.error.TweepError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    print(f'Got {len(tweets)} Tweets!!')\n",
    "    tweets = [tweet._json for tweet in tweets]\n",
    "    return pd.DataFrame(data=tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example. Say we want to download 10 tweets with the hashtag #COVID-19. We can do this in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 10 Tweets!!\n"
     ]
    }
   ],
   "source": [
    "covid19_tweets_df = get_tags(api_dict=api_dict, tags_list=['COVID19'], language='en', count_int=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output dataframe has 10 rows (one tweet per row) and 28 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 29)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid19_tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 28 columns listed below give a lot of details on the tweets, including the date of creation, the tweet ID and the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities',\n",
       "       'metadata', 'source', 'in_reply_to_status_id',\n",
       "       'in_reply_to_status_id_str', 'in_reply_to_user_id',\n",
       "       'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo',\n",
       "       'coordinates', 'place', 'contributors', 'retweeted_status',\n",
       "       'is_quote_status', 'retweet_count', 'favorite_count', 'favorited',\n",
       "       'retweeted', 'lang', 'possibly_sensitive', 'quoted_status_id',\n",
       "       'quoted_status_id_str', 'quoted_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid19_tweets_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we focus on the text, here are the first 5 tweets we picked up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RT @KKMPutrajaya: Terkini. Kes baharu hari ini 4,008 kes dengan 11 lagi kematian. Kes tertinggi Selangor, KL, Johor, Sabah dan Sarawak. 16‚Ä¶    \n",
       "1    RT @Orla_Hegarty: #Covid19 #schools Let‚Äôs talk about transmission of respiratory infectious diseases https://t.co/gkIcsjaguN via @ShellyMBo‚Ä¶   \n",
       "2    RT @KKMPutrajaya: Status Terkini #COVID19, 20 Januari 2021 \\nKes sembuh=2,374\\nJumlah kes sembuh=127,662 kes \\nKes baharu positif=4,008 kes (4‚Ä¶\n",
       "3    RT @AngelBl21345102: Feliz d√≠a Twiteros la etiqueta de hoy esüëá ‚úîÔ∏è#VacunasParaLosPueblosüíâüíâüíâüíâüíâüíâ\\n\\n   üì¢Estados miembros del #ALBATCP acordaron‚Ä¶  \n",
       "4    RT @vane_B591: La hipocres√≠a de @evoespueblo mientras ‚ÄúEl‚Äù es atendido en una cl√≠nica privada con un equipo de m√©dicos la gran mayor√≠a de l‚Ä¶   \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid19_tweets_df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option when downloading tweets is to focus on the tweets from one or several specific users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below takes as input:\n",
    "- `screen_name` the screen name of a Twitter user (another name for a Twitter handle)\n",
    "- `api` the authenticated API credentials\n",
    "\n",
    "It returns a tuple containing the timeline of that Twitter user in a Pandas dataframe format and, the error message from Tweepy in case there is one. The upper bound of the number of tweets to download is set to 3200 (`count` argument) to avoid API rate limit errors. We also choose the extended `tweet_mode` to avoid the truncating of tweets the Tweepy tool does by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeline(screen_name, api):\n",
    "    timeline = []\n",
    "    error = None\n",
    "    # Collect All Statuses in Timeline\n",
    "    try:\n",
    "        cursor = tweepy.Cursor(\n",
    "            api.user_timeline,\n",
    "            screen_name=screen_name,\n",
    "            tweet_mode=\"extended\",\n",
    "            count=3200,\n",
    "            include_rts=False).items()\n",
    "\n",
    "        for status in cursor:\n",
    "            timeline.append(status._json)\n",
    "    except tweepy.error.TweepError as e:\n",
    "        error = str(e)\n",
    "    return pd.DataFrame(timeline), error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's download Joe Biden's timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Jan 20 03:20:00 +0000 2021</td>\n",
       "      <td>1351731172989050882</td>\n",
       "      <td>1351731172989050882</td>\n",
       "      <td>Tonight, in Washington, D.C. and across the nation, we came together to honor the over 400,000 Americans we‚Äôve lost to COVID-19. The last year has tested us in unimaginable ways, but now it‚Äôs time we begin to heal and overcome ‚Äî together. https://t.co/DuWhN1xjNO</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 238]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [], 'media': [{'id': 1351729929906434050, 'id_str': '1351729929906434050', 'indices': [239, 262], 'media_url': 'http://pbs.twimg.com/media/EsJPNaBWMAIk878.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EsJPNaBWMAIk878.jpg', 'url': 'https://t.co/DuWhN1xjNO', 'display_url': 'pic.twitter.com/DuWhN1xjNO', 'expanded_url': 'https://twitter.com/JoeBiden/status/1351731172989050882/photo/1', 'type': 'photo', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1200, 'h': 793, 'resize': 'fit'}, 'small': {'w': 680, 'h': 450, 'resize': 'fit'}, 'large': {'w': 2048, 'h': 1354, 'resize': 'fit'}}}]}</td>\n",
       "      <td>{'media': [{'id': 1351729929906434050, 'id_str': '1351729929906434050', 'indices': [239, 262], 'media_url': 'http://pbs.twimg.com/media/EsJPNaBWMAIk878.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EsJPNaBWMAIk878.jpg', 'url': 'https://t.co/DuWhN1xjNO', 'display_url': 'pic.twitter.com/DuWhN1xjNO', 'expanded_url': 'https://twitter.com/JoeBiden/status/1351731172989050882/photo/1', 'type': 'photo', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1200, 'h': 793, 'resize': 'fit'}, 'small': {'w': 680, 'h': 450, 'resize': 'fit'}, 'large': {'w': 2048, 'h': 1354, 'resize': 'fit'}}}]}</td>\n",
       "      <td>&lt;a href=\"https://studio.twitter.com\" rel=\"nofollow\"&gt;Twitter Media Studio&lt;/a&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>29815</td>\n",
       "      <td>291528</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Wed Jan 20 03:20:00 +0000 2021  1351731172989050882  1351731172989050882   \n",
       "\n",
       "                                                                                                                                                                                                                                                                full_text  \\\n",
       "0  Tonight, in Washington, D.C. and across the nation, we came together to honor the over 400,000 Americans we‚Äôve lost to COVID-19. The last year has tested us in unimaginable ways, but now it‚Äôs time we begin to heal and overcome ‚Äî together. https://t.co/DuWhN1xjNO   \n",
       "\n",
       "   truncated display_text_range  \\\n",
       "0  False      [0, 238]            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   entities  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [], 'media': [{'id': 1351729929906434050, 'id_str': '1351729929906434050', 'indices': [239, 262], 'media_url': 'http://pbs.twimg.com/media/EsJPNaBWMAIk878.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EsJPNaBWMAIk878.jpg', 'url': 'https://t.co/DuWhN1xjNO', 'display_url': 'pic.twitter.com/DuWhN1xjNO', 'expanded_url': 'https://twitter.com/JoeBiden/status/1351731172989050882/photo/1', 'type': 'photo', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1200, 'h': 793, 'resize': 'fit'}, 'small': {'w': 680, 'h': 450, 'resize': 'fit'}, 'large': {'w': 2048, 'h': 1354, 'resize': 'fit'}}}]}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          extended_entities  \\\n",
       "0  {'media': [{'id': 1351729929906434050, 'id_str': '1351729929906434050', 'indices': [239, 262], 'media_url': 'http://pbs.twimg.com/media/EsJPNaBWMAIk878.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EsJPNaBWMAIk878.jpg', 'url': 'https://t.co/DuWhN1xjNO', 'display_url': 'pic.twitter.com/DuWhN1xjNO', 'expanded_url': 'https://twitter.com/JoeBiden/status/1351731172989050882/photo/1', 'type': 'photo', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1200, 'h': 793, 'resize': 'fit'}, 'small': {'w': 680, 'h': 450, 'resize': 'fit'}, 'large': {'w': 2048, 'h': 1354, 'resize': 'fit'}}}]}   \n",
       "\n",
       "                                                                         source  \\\n",
       "0  <a href=\"https://studio.twitter.com\" rel=\"nofollow\">Twitter Media Studio</a>   \n",
       "\n",
       "   in_reply_to_status_id  ... retweet_count  favorite_count favorited  \\\n",
       "0 NaN                     ...  29815         291528          False      \n",
       "\n",
       "  retweeted possibly_sensitive lang quoted_status_id quoted_status_id_str  \\\n",
       "0  False     False              en  NaN               NaN                   \n",
       "\n",
       "  quoted_status_permalink  quoted_status  \n",
       "0  NaN                     NaN            \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joe_biden_timeline_df = get_timeline(screen_name='JoeBiden', api=get_auth(api_dict))[0]\n",
    "joe_biden_timeline_df.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully downloaded 3028 tweets (one tweet per row) from Joe Biden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 30)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joe_biden_timeline_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe contains 30 columns with specific information on each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'id', 'id_str', 'full_text', 'truncated',\n",
       "       'display_text_range', 'entities', 'extended_entities', 'source',\n",
       "       'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
       "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
       "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
       "       'contributors', 'is_quote_status', 'retweet_count', 'favorite_count',\n",
       "       'favorited', 'retweeted', 'possibly_sensitive', 'lang',\n",
       "       'quoted_status_id', 'quoted_status_id_str', 'quoted_status_permalink',\n",
       "       'quoted_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joe_biden_timeline_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's get some users from Pakistan and later we will use their tweets.\n",
    "First we will use Imran Khan (Prime minister of Pakistan) Account as a source to gather tweets from Pakistan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we will grab a list of 300 of his followers.\n",
    "In order to achieve this we will define the following function:\n",
    "\n",
    "The function below takes an input:\n",
    "- `user_names` a list of screen names whose user_ids we want\n",
    "- `amount` the amount of users we wish to obtain\n",
    "\n",
    "It then returns the list of `followers` that follow each user up to `amount` per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_followers(user_names, amount):\n",
    "    api = get_auth(api_dict)\n",
    "    followers = []\n",
    "    for user_name in user_names:\n",
    "        try:\n",
    "            for follower in tweepy.Cursor(api.followers, user_name).items(amount):\n",
    "                followers.extend([follower.screen_name])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    print(f'Got {len(followers)} followers!!')\n",
    "    return followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 100 followers!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Atii_Jee',\n",
       " 'AzemJutt',\n",
       " 'MMuneexa',\n",
       " 'Meganat10843861',\n",
       " 'AftabaliMemon15',\n",
       " 'NasrullahPasto1',\n",
       " 'AimeeeAwan',\n",
       " 'SaimSajawal',\n",
       " 'Muqadas37606062',\n",
       " 'HaroonS26516795']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_names = ['ImranKhanPTI']\n",
    "followers_screen_names = get_followers(user_names, 100)\n",
    "# print 10 first users\n",
    "followers_screen_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When wanting to draw policy insights from tweets, one timeline is usually not enough. We have prepared to download and save the timelines of several users. We first define an output path `path_to_timelines` where the timelines will be saved. Please modify it with a local path on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_timelines = './data/timelines'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below takes an input:\n",
    "- `downloaded_screen_name_list` a list of screen names whose timelines were downloaded\n",
    "- `output_id` an ID to differentiate different outputs\n",
    "- `user_index` the rank of the user screen name in the list of screen names to download\n",
    "- `timelines` the tweet data in pandas dataframe format\n",
    "\n",
    "It then saves the dataframe in the `path_to_timelines` folder in a pickle format. The file name is defined as: `timelines-NB_DOWNLOADED_TIMELINES-OUTPUT_ID.pkl` where `NB_DOWNLOADED_TIMELINES` is the number of downloaded timelines and `OUTPUT_ID` is a randomly generated ID. A `success` text file is also saved and informs on the filename where the timeline of a specific user is saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_timelines(downloaded_screen_name_list, output_id, user_index, timelines):\n",
    "    filename = 'timelines-' + str(len(downloaded_screen_name_list)) + '-' + output_id + '.pkl'\n",
    "\n",
    "    print('Process', 'processed', str(int(user_index) + 1 ), 'timelines with latest output file:',\n",
    "          os.path.join(path_to_timelines, filename))\n",
    "    dir_path = os.path.join(path_to_timelines)\n",
    "    # Save as list of dict discarding index\n",
    "    timelines.to_pickle(os.path.join(dir_path, filename))\n",
    "\n",
    "    # Save User Id and File In Which Its Timeline Was Saved\n",
    "    with open(os.path.join(path_to_timelines, 'success'), 'a', encoding='utf-8') as file:\n",
    "        for downloaded_screen_name in downloaded_screen_name_list:\n",
    "            file.write(f'{downloaded_screen_name}\\t{filename}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `cutoff` variable which works in the following manner: when the number of downloaded timelines reaches `cutoff`, these timelines are saved and then deleted from memory. The idea is to avoid losing already downloaded data in case of an error from the Tweepy client. Here, we define `cutoff` as equal to 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below combines the functions `get_timeline` and `save_timelines`. It takes as input:\n",
    "- `api_dict` the API credentials in a dictionary format\n",
    "- `screen_name_list` a list of users screen names\n",
    "\n",
    "It then downloads the timelines of each of the users in `screen_name_list` and saves these timelines in the `path_to_timelines` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def download_timelines(api_dict, screen_name_list):\n",
    "    # Create Access For Block of Users\n",
    "    api = get_auth(api_dict)\n",
    "    # Initialize Output File ID\n",
    "    output_id = str(uuid.uuid4())\n",
    "    # Initialize DataFrame\n",
    "    timelines = pd.DataFrame()\n",
    "    # Initialize Downloaded User List\n",
    "    downloaded_screen_name_list = []\n",
    "    for user_index, screen_name in enumerate(screen_name_list):\n",
    "        # Try Downloading Timeline\n",
    "        timeline, error = get_timeline(screen_name, api)\n",
    "        if error is not None:\n",
    "            print(screen_name, error)\n",
    "            continue\n",
    "        # Append\n",
    "        timelines = pd.concat([timelines, timeline], sort=False)\n",
    "        downloaded_screen_name_list.append(screen_name)\n",
    "        # Save after <cutoff> timelines\n",
    "        if len(downloaded_screen_name_list) == cutoff:\n",
    "            save_timelines(downloaded_screen_name_list, output_id, user_index, timelines)\n",
    "            # Reset Output File ID, Data, and Downloaded Users\n",
    "            del timelines, downloaded_screen_name_list\n",
    "            output_id = str(uuid.uuid4())\n",
    "            timelines = pd.DataFrame()\n",
    "            downloaded_screen_name_list = []\n",
    "    # Save the rest of the timelines\n",
    "    save_timelines(downloaded_screen_name_list, output_id, len(screen_name_list) - 1, timelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olliddahsra Twitter error response: status code = 401\n",
      "WlDi5r6z0UQwBY7 Twitter error response: status code = 404\n",
      "Process processed 100 timelines with latest output file: ./data/timelines\\timelines-98-f9ff4fae-05bf-472a-be95-6d79338a554d.pkl\n"
     ]
    }
   ],
   "source": [
    "download_timelines(api_dict, screen_name_list = followers_screen_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download social network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last Tweepy feature we cover in this tutorial is the possibility to download a list of Twitter accounts that are followed by a specific Twitter account. The function below takes as input:\n",
    "- `api_dict` the API credentials in a dictionary format\n",
    "- `screen_name_list` a list of user screen names.\n",
    "\n",
    "This function will download the list of usernames each user in the `screen_name_list` follows and return the results as a dictionary, with screen_names of users given as input as keys and, a list of the users they follow as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_friends(api_dict, screen_name_list):\n",
    "    api = get_auth(api_dict)\n",
    "    friends_dict = dict()\n",
    "    for screen_name in screen_name_list:\n",
    "        friends_list = list()\n",
    "        try:\n",
    "            for friend_ids in tweepy.Cursor(api.friends_ids, screen_name=screen_name).pages():\n",
    "                friends_list.extend(friend_ids)\n",
    "            friends_name_list = [user.screen_name for user in api.lookup_users(user_ids=friends_list)]\n",
    "            friends_dict[screen_name] = friends_name_list\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return friends_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an example with Joe Biden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends_dict = get_friends(api_dict, ['JoeBiden'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can find the list of users Joe Biden and Donald Trump respectively follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Twitter users Joe Biden follows:**************\n",
      "['teachcardona', 'AliMayorkas', 'ABlinken', 'JanetYellen', 'neeratanden', 'XavierBecerra', 'mlfudge', 'DenisMcDonough', 'PeteButtigieg', 'DebHaalandNM', 'JenGranholm', 'Michael_S_Regan', 'LloydAustin', 'Mariska', 'BidenInaugural', 'Transition46', 'BlueAmerica22', 'DouglasEmhoff', 'KamalaHarris', 'JoeForNV', 'JoeForSC', 'JoeForNH', 'JoeForIA', 'TeamJoe', 'De11eDonne', 'ladygaga', 'ItsOnUs', 'DrBiden', 'UDBidenInst', 'BidenCancer', 'PennBiden', 'ObamaFoundation', 'livelihood2017', 'bidenfoundation', 'timkaine', 'HillaryClinton', 'DrBiden44', 'ObamaWhiteHouse', 'WhiteHouse', 'VP44', 'VP', 'BeauBidenFdn', 'TheDemocrats', 'MichelleObama', 'BarackObama']\n"
     ]
    }
   ],
   "source": [
    "print('**************Twitter users Joe Biden follows:**************')\n",
    "print(friends_dict['JoeBiden'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}